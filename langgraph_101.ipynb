{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca539880-3be1-4991-b1b3-913c0494d902",
   "metadata": {},
   "source": [
    "# LangGraph Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56172d-3665-4acf-9bcd-8373be0c0096",
   "metadata": {},
   "source": [
    "Here we follow [this tutorial](https://github.com/LangGraph-GUI/LangGraph-learn/tree/main/02%20LangGraph%20Hello%20World), [this tutorial](https://github.com/LangGraph-GUI/LangGraph-learn/tree/main/03%20Graph%20Chain%20Hello%20World), and [this tutorial](https://github.com/LangGraph-GUI/LangGraph-learn/tree/main/04%20State%20Graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cda0a9-bcb7-47dc-b796-0ab815afe97d",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736e25a-986c-4bfc-a244-b38a5850c5b0",
   "metadata": {},
   "source": [
    "1. `ollama` server\n",
    "2. `langchain-ollama`\n",
    "3. `langchain-core`\n",
    "4. `langgraph`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c598a-a7c4-421a-93f0-109450d65506",
   "metadata": {},
   "source": [
    "## Building a Simple Workflow without LLMs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93801f-04db-4b13-ad16-df53b9defa09",
   "metadata": {},
   "source": [
    "In [this demo](https://github.com/LangGraph-GUI/LangGraph-learn/tree/main/02%20LangGraph%20Hello%20World), two nodes in a chained fashion will cooperate to construct a greeting string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12591aa9-59d2-47d9-9b34-09b571a73347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8fd945-fbf9-4e2e-b7de-34e7c185bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two simple functions to be used in the workflow\n",
    "def func_1(x1):\n",
    "    return f\"Hello {x1}.\"\n",
    "\n",
    "def func_2(x2):\n",
    "    return f\"{x2} How are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e665aa4f-3989-4350-afae-a57ddbb3623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_1_NAME = 'node_1'\n",
    "NODE_2_NAME = 'node_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e9564d-045b-4e6c-add7-b6f8eb524a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph where each function is a node\n",
    "workflow = Graph()\n",
    "workflow.add_node(NODE_1_NAME, func_1)\n",
    "workflow.add_node(NODE_2_NAME, func_2)\n",
    "# also define edges to connect the nodes\n",
    "workflow.add_edge(NODE_1_NAME, NODE_2_NAME)\n",
    "# finally set the entry and finish points of the workflow\n",
    "workflow.set_entry_point(NODE_1_NAME)\n",
    "_ = workflow.set_finish_point(NODE_2_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4abfe2-12f6-4bae-9d1d-a3974aa4b24e",
   "metadata": {},
   "source": [
    "Now we have a workflow as a graph: START --> node_1 --> node_2 --> END."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd9af1f-9de4-4e9f-8273-dc54427b9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ff2a2b-510e-445f-9354-512e3c2731e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mike. How are you?\n"
     ]
    }
   ],
   "source": [
    "# invoke the compiled workflow\n",
    "res = app.invoke(\"Mike\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed902c99-9971-49d6-911e-bc573d6c5292",
   "metadata": {},
   "source": [
    "## Building a Workflow that Utilizes an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a780d-0a87-44e2-8024-3aaa8597bb2a",
   "metadata": {},
   "source": [
    "In [this demo](https://github.com/LangGraph-GUI/LangGraph-learn/tree/main/03%20Graph%20Chain%20Hello%20World), an agent will accept the user's request to write a story into a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a332a1-f0e8-4422-a82a-44d135eb85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f67d4ec7-0565-4c0f-b819-184e96b8d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ChatOllama model with desired parameters\n",
    "# https://pypi.org/project/langchain-ollama/\n",
    "# https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "# https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html\n",
    "llm = ChatOllama(model=\"qwen2.5:7b\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cec6f2d-5264-40b7-bc43-4c0dfd7f7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a prompt template for the agent\n",
    "template = \"\"\"\n",
    "    You are an excellent writer capable of producing amazing stories and analyses.\n",
    "    Question: {question}\n",
    "    On the top level, the output should contain a \"filename\" JSON key to capture any file name provided by the user. It should also contain a \"content\" JSON key to place your generation result.\n",
    "    If the user does not provide a file name, try to randomly generate one for the user.\n",
    "    The format of the \"content\" JSON key's value depends on the user's request. By default, it should be a single string of Markdown style.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d614ee84-099e-4d18-b371-97db72c61c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a writer agent to output strict json text\n",
    "WRITER_NAME = 'writer'\n",
    "def Writer(question):\n",
    "    formatted_prompt = prompt.format(question=question)\n",
    "    print(f'{WRITER_NAME}: Writing...')\n",
    "    generation = llm.invoke(formatted_prompt)\n",
    "    print(f'{WRITER_NAME}: Finished Writing.')\n",
    "    return generation.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e166891-ff84-4755-ae43-79f9ab0c30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "OUT_DIR = 'out/'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# define a dumper to get LLM's response JSON and actually store the generated text to a file\n",
    "DUMPER_NAME = 'dumper'\n",
    "def Dumper(result_json):\n",
    "    print(f'{DUMPER_NAME}: Loading JSON...')\n",
    "    data = json.loads(result_json)\n",
    "    print(f'{DUMPER_NAME}: JSON loaded successfully.')\n",
    "    # extract outputs\n",
    "    content = data.get('content', \"\")\n",
    "    filename = data.get('filename', \"output.md\")\n",
    "    # write\n",
    "    print(f'{DUMPER_NAME}: Writing to {filename}...')\n",
    "    with open(os.path.join(f'out/{filename}'), 'w') as file:\n",
    "        file.write(content)\n",
    "    print(f'{DUMPER_NAME}: Finished writing.')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d73b043-0e58-4ab7-a0f7-a6fba844d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph where each function is a node\n",
    "workflow = Graph()\n",
    "workflow.add_node(WRITER_NAME, Writer)\n",
    "workflow.add_node(DUMPER_NAME, Dumper)\n",
    "# also define edges to connect the nodes\n",
    "workflow.add_edge(WRITER_NAME, DUMPER_NAME)\n",
    "# finally set the entry and finish points of the workflow\n",
    "workflow.set_entry_point(WRITER_NAME)\n",
    "_ = workflow.set_finish_point(DUMPER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc57a9c-8ef5-4c1f-8fc5-3c74d3f44251",
   "metadata": {},
   "source": [
    "Now test~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1790e390-2edb-473e-8713-a707974aae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88eb912a-503d-4afd-b6d5-65fb11ad86bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# invoke the compiled workflow\n",
    "def run(prompt):\n",
    "    res = app.invoke(prompt)\n",
    "    print(f'> JSON dict keys: {res.keys()}')\n",
    "    print(f'> File name: {res[\"filename\"]}')\n",
    "    print(res['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6082ebf3-d6f5-4acc-85df-d82fcbbdcd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer: Writing...\n",
      "writer: Finished Writing.\n",
      "dumper: Loading JSON...\n",
      "dumper: JSON loaded successfully.\n",
      "dumper: Writing to wakeup.md...\n",
      "dumper: Finished writing.\n",
      "> JSON dict keys: dict_keys(['filename', 'content'])\n",
      "> File name: wakeup.md\n",
      "# How to Wake Up Early in the Morning\n",
      "\n",
      "## Introduction\n",
      "Waking up early can have numerous benefits such as better productivity and stress management. Here are some tips on how to establish an early morning routine.\n",
      "\n",
      "## Establish a Consistent Sleep Schedule\n",
      "Try to go to bed and wake up at the same time every day, even on weekends. This will help regulate your body's internal clock and make waking up easier.\n",
      "\n",
      "## Create a Bedtime Routine\n",
      "Engage in calming activities before bedtime such as reading or listening to soothing music. Avoid screens an hour before bed to help you wind down more effectively.\n",
      "\n",
      "## Use Alarms Strategically\n",
      "Set multiple alarms at progressively earlier times, but avoid setting too many as it can be overwhelming and lead to frustration. Place your alarm on the other side of the room so you have to get out of bed to turn it off.\n",
      "\n",
      "## Make Your Room Uncomfortable for Sleeping\n",
      "Ensure that your bedroom is cool, dark, and quiet. If noise is an issue, consider using a white noise machine or earplugs. A less comfortable sleeping environment can make waking up more natural when the time comes.\n",
      "\n",
      "## Create Early Morning Motivation\n",
      "Visualize why you want to wake up early, whether it's for personal goals, health benefits, or just to enjoy some quiet time before starting your day. Write down these reasons and place them in a visible spot to remind yourself each morning.\n"
     ]
    }
   ],
   "source": [
    "run('Suggest how to wake up early in the morning - in a file named \"wakeup.md\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a86e9f-2ba1-483f-99a0-4c69c129caae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer: Writing...\n",
      "writer: Finished Writing.\n",
      "dumper: Loading JSON...\n",
      "dumper: JSON loaded successfully.\n",
      "dumper: Writing to the_ultimate_goal_of_life.md...\n",
      "dumper: Finished writing.\n",
      "> JSON dict keys: dict_keys(['filename', 'content'])\n",
      "> File name: the_ultimate_goal_of_life.md\n",
      "# The Ultimate Goal of Life: A Quest for Meaning and Fulfillment\n",
      "\n",
      "The ultimate goal of life is a deeply personal and subjective question that has puzzled philosophers, theologians, and thinkers throughout history. While there isn't one single answer that applies to everyone, many individuals seek meaning and fulfillment through a combination of internal and external factors.\n",
      "\n",
      "## The Search for Purpose\n",
      "\n",
      "At the core of finding one's ultimate goal lies the search for purpose. This can manifest in various ways, such as:\n",
      "\n",
      "- **Personal Development**: Continuously growing and improving oneself to reach one’s full potential.\n",
      "- **Service**: Contributing to others or society, whether through volunteering, mentoring, or other forms of assistance.\n",
      "- **Passion Projects**: Engaging in activities that bring joy and satisfaction, which can include hobbies, sports, art, or creative pursuits.\n",
      "\n",
      "## Fulfillment Through Relationships\n",
      "\n",
      "Another significant aspect of life's ultimate goal involves the connections we form with others. Human beings are inherently social creatures, and meaningful relationships contribute significantly to our sense of fulfillment:\n",
      "\n",
      "- **Family and Friends**: Building strong bonds with loved ones provides emotional support and a sense of belonging.\n",
      "- **Community Engagement**: Participating in community events or clubs can foster a sense of connection and purpose beyond the individual self.\n",
      "\n",
      "## The Pursuit of Knowledge and Wisdom\n",
      "\n",
      "The quest for knowledge and wisdom is another path many take to find their ultimate goal:\n",
      "\n",
      "- **Education and Learning**: Continuously expanding one’s understanding through formal education, reading, or online resources.\n",
      "- **Philosophical Inquiry**: Engaging with deep questions about existence, ethics, and the nature of reality can lead to profound insights.\n",
      "\n",
      "## Spirituality and the Soul's Journey\n",
      "\n",
      "For those who believe in a spiritual dimension, their ultimate goal may be tied to finding deeper connections with something beyond the material world:\n",
      "\n",
      "- **Religious Practice**: Following a faith that provides guidance on living a righteous life.\n",
      "- **Meditation and Reflection**: Exploring inner peace and understanding through meditation, mindfulness, or contemplative practices.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "In essence, the ultimate goal of life is not a static destination but an ongoing journey. It involves balancing these various aspects to create a fulfilling life that resonates deeply with one's individual values and beliefs. Whether you find your purpose in personal growth, service, relationships, knowledge, or spirituality, the key is finding what truly fulfills you.\n"
     ]
    }
   ],
   "source": [
    "run('What is the ultimate goal of life?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4069c71-bed4-4c28-b121-0d465d96a9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer: Writing...\n",
      "writer: Finished Writing.\n",
      "dumper: Loading JSON...\n",
      "dumper: JSON loaded successfully.\n",
      "dumper: Writing to merge_sort_program.py...\n",
      "dumper: Finished writing.\n",
      "> JSON dict keys: dict_keys(['filename', 'content'])\n",
      "> File name: merge_sort_program.py\n",
      "# Merge Sort in Python\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Merge sort is a divide-and-conquer algorithm that divides an array into halves, sorts each half, and then merges them back together. This example demonstrates how to implement merge sort in Python.\n",
      "\n",
      "## Code Implementation\n",
      "```python\n",
      "def merge_sort(arr):\n",
      "    if len(arr) > 1:\n",
      "        mid = len(arr) // 2\n",
      "        left_half = arr[:mid]\n",
      "        right_half = arr[mid:]\n",
      "\n",
      "        # Recursive call on each half\n",
      "        merge_sort(left_half)\n",
      "        merge_sort(right_half)\n",
      "\n",
      "        # Two iterators for traversing the two halves\n",
      "        i = j = k = 0\n",
      "\n",
      "        # Copy data to temp arrays left_half and right_half\n",
      "        while i < len(left_half) and j < len(right_half):\n",
      "            if left_half[i] < right_half[j]:\n",
      "                arr[k] = left_half[i]\n",
      "                i += 1\n",
      "            else:\n",
      "                arr[k] = right_half[j]\n",
      "                j += 1\n",
      "            k += 1\n",
      "\n",
      "        # Checking if any element was left\n",
      "        while i < len(left_half):\n",
      "            arr[k] = left_half[i]\n",
      "            i += 1\n",
      "            k += 1\n",
      "\n",
      "        while j < len(right_half):\n",
      "            arr[k] = right_half[j]\n",
      "            j += 1\n",
      "            k += 1\n",
      "```\n",
      "\n",
      "## Example Usage\n",
      "\n",
      "```python\n",
      "if __name__ == '__main__':\n",
      "    test_array = [64, 34, 25, 12, 22, 11, 90]\n",
      "    print('Given array:', test_array)\n",
      "    merge_sort(test_array)\n",
      "    print('Sorted array:', test_array)\n",
      "```\n",
      "\n",
      "## Output\n",
      "\n",
      "```plaintext\n",
      "Given array: [64, 34, 25, 12, 22, 11, 90]\n",
      "Sorted array: [11, 12, 22, 25, 34, 64, 90]\n",
      "```\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "This implementation of merge sort demonstrates how to effectively use recursion and merging to sort an array. The code is straightforward and can be adapted for various sorting needs.\n"
     ]
    }
   ],
   "source": [
    "run('In Python, how to build a simple merge sort program?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f2c6e8-355d-4e1d-918a-3fa5e799a539",
   "metadata": {},
   "source": [
    "## Building a State Machine (No LLM Integration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6e00c-8fa0-452e-a166-d351e41997bf",
   "metadata": {},
   "source": [
    "In [this demo](https://github.com/LangGraph-GUI/LangGraph-learn/tree/main/04%20State%20Graph), a buyer will keep buying lottery round by round until he wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9aa4b68-e66c-47af-95ea-00a1c7f0fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e65253e-e507-4144-b6d4-80e3a485619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Representation\n",
    "class LotteryState(TypedDict):\n",
    "    buy_num: int\n",
    "    prize_num: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cadfc8d-9624-44c3-9bf6-9fb4efb4c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buy Lottery Node\n",
    "BUYER_NODE_NAME = 'buyer'\n",
    "def Buyer(state: LotteryState):\n",
    "    rand_num = random.randint(0, 2) # 0, 1, 2\n",
    "    print('-------------------------')\n",
    "    print(f'\\t> buy number: {rand_num}')\n",
    "    state['buy_num'] = rand_num\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ac56a65-d9d6-4240-9140-8189e24b0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prize Node\n",
    "PRIZE_NODE_NAME = 'prize'\n",
    "def Prize(state: LotteryState):\n",
    "    prize_num = random.randint(0, 2) # 0, 1, 2\n",
    "    print(f'\\t> prize number: {prize_num}')\n",
    "    state['prize_num'] = prize_num\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b230688-1f63-4a67-ad69-b34f5f2a2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Edge (Conditional)\n",
    "def check_result(state: LotteryState):\n",
    "    print(f'\\t> State: {state}')\n",
    "    if state['buy_num'] == state['prize_num']:\n",
    "        print('\\t> You win! Go home.')\n",
    "        return END\n",
    "    else:\n",
    "        print('\\t> You missed. Buy again.')\n",
    "        return BUYER_NODE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbacf65-bcf3-4f89-8e5d-5777f29919f7",
   "metadata": {},
   "source": [
    "- State Graph: official doc - [intro](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) and [reference](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.get_graph).\n",
    "- Conditional Edge: official doc - [reference](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph.add_conditional_edges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f48e9e58-eb89-473e-944f-d7134bb12b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph\n",
    "workflow = StateGraph(LotteryState)\n",
    "workflow.add_node(BUYER_NODE_NAME, Buyer)\n",
    "workflow.add_node(PRIZE_NODE_NAME, Prize)\n",
    "workflow.set_entry_point(BUYER_NODE_NAME)\n",
    "workflow.add_edge(BUYER_NODE_NAME, PRIZE_NODE_NAME)\n",
    "_ = workflow.add_conditional_edges(PRIZE_NODE_NAME, check_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba23459-bcf5-4ec2-8772-21485578af7d",
   "metadata": {},
   "source": [
    "Now test~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81aef64f-def7-4707-8909-021ef699bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b65eee-6dd7-467e-9a03-20bf60d00ca6",
   "metadata": {},
   "source": [
    "Streaming: official doc - [intro](https://langchain-ai.github.io/langgraph/concepts/streaming/) and [reference](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54ec9a47-b767-43e7-a744-4f8baba5889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "\t> buy number: 2\n",
      "{'buyer': {'buy_num': 2}}\n",
      "\t> prize number: 1\n",
      "\t> State: {'buy_num': 2, 'prize_num': 1}\n",
      "\t> You missed. Buy again.\n",
      "{'prize': {'buy_num': 2, 'prize_num': 1}}\n",
      "-------------------------\n",
      "\t> buy number: 2\n",
      "{'buyer': {'buy_num': 2, 'prize_num': 1}}\n",
      "\t> prize number: 2\n",
      "\t> State: {'buy_num': 2, 'prize_num': 2}\n",
      "\t> You win! Go home.\n",
      "{'prize': {'buy_num': 2, 'prize_num': 2}}\n"
     ]
    }
   ],
   "source": [
    "# invoke the compiled workflow\n",
    "for s in app.stream(LotteryState()):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc615c2-6dfd-4813-a979-0dedfecbd70e",
   "metadata": {},
   "source": [
    "## Nested Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ea95d-9d0d-4525-b276-3d6722b2f5fa",
   "metadata": {},
   "source": [
    "In LangGraph, graphs can be nested together where nodes can be subgraphs. Check [this demo](https://github.com/LangGraph-GUI/LangGraph-learn/tree/main/08%20SubGraph) as an example. We will not demonstrate here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Edge AI",
   "language": "python",
   "name": "edge-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
